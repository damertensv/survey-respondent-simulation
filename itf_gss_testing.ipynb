{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24096221",
   "metadata": {},
   "source": [
    "# GSS testing notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f7bdc",
   "metadata": {},
   "source": [
    "## How to preproceess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a4bff",
   "metadata": {},
   "source": [
    "### Loading the GSS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "15b544e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = (3309, 813)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileversion</th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>abany</th>\n",
       "      <th>abanyg</th>\n",
       "      <th>abdefect</th>\n",
       "      <th>abdefectg</th>\n",
       "      <th>abhlth</th>\n",
       "      <th>abhlthg</th>\n",
       "      <th>abnomore</th>\n",
       "      <th>...</th>\n",
       "      <th>wrkstat</th>\n",
       "      <th>wrkwayup</th>\n",
       "      <th>wrldgovt</th>\n",
       "      <th>wtssnrps</th>\n",
       "      <th>wtssps</th>\n",
       "      <th>xmarsex</th>\n",
       "      <th>xmovie</th>\n",
       "      <th>xmoviey</th>\n",
       "      <th>xnorcsiz</th>\n",
       "      <th>yousup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7224.2</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.369490</td>\n",
       "      <td>1.889989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7224.2</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.391160</td>\n",
       "      <td>1.152265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7224.2</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.171199</td>\n",
       "      <td>0.915609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7224.2</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.735830</td>\n",
       "      <td>2.288064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7224.2</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.272915</td>\n",
       "      <td>1.005427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fileversion    year   id  abany  abanyg  abdefect  abdefectg  abhlth  \\\n",
       "0       7224.2  2024.0  1.0    NaN     NaN       NaN        NaN     NaN   \n",
       "1       7224.2  2024.0  2.0    NaN     NaN       NaN        NaN     NaN   \n",
       "2       7224.2  2024.0  3.0    1.0     1.0       NaN        1.0     NaN   \n",
       "3       7224.2  2024.0  4.0    2.0     NaN       2.0        NaN     2.0   \n",
       "4       7224.2  2024.0  5.0    2.0     2.0       NaN        2.0     NaN   \n",
       "\n",
       "   abhlthg  abnomore  ...  wrkstat  wrkwayup  wrldgovt  wtssnrps    wtssps  \\\n",
       "0      NaN       NaN  ...      1.0       4.0       NaN  2.369490  1.889989   \n",
       "1      NaN       NaN  ...      5.0       2.0       3.0  1.391160  1.152265   \n",
       "2      1.0       NaN  ...      5.0       NaN       2.0  1.171199  0.915609   \n",
       "3      NaN       2.0  ...      2.0       2.0       NaN  2.735830  2.288064   \n",
       "4      1.0       NaN  ...      5.0       NaN       3.0  1.272915  1.005427   \n",
       "\n",
       "   xmarsex  xmovie  xmoviey  xnorcsiz  yousup  \n",
       "0      NaN     1.0      NaN       4.0     NaN  \n",
       "1      NaN     NaN      4.0       4.0     NaN  \n",
       "2      1.0     2.0      NaN       4.0     NaN  \n",
       "3      1.0     NaN      NaN       4.0     NaN  \n",
       "4      1.0     2.0      NaN       4.0     NaN  \n",
       "\n",
       "[5 rows x 813 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "def from_gss(file_path: str, n_sample: int | None = None, random_state: int = 42) -> tuple[pd.DataFrame, Any]:\n",
    "    df, meta = pyreadstat.read_sav(file_path)\n",
    "    if n_sample is not None:\n",
    "        df = df.sample(n=n_sample, random_state=random_state).reset_index(drop=True)\n",
    "    return df, meta\n",
    "\n",
    "data, meta = from_gss(\"./datasets/2024_spss/2024/GSS2024.sav\")\n",
    "print(f\"data.shape = {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358835d5",
   "metadata": {},
   "source": [
    "### Integer, floating, or nominal/ordinal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6ce70834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def infer_resp_type(col: str, df: pd.DataFrame, meta: Any) -> Literal[\"int\", \"float\", \"nominal/ordinal\", \"unknown\"]:\n",
    "    unique_vals = df[col].dropna().unique()\n",
    "    val2txt = {k: v for k, v in meta.variable_value_labels.get(col, {}).items() if 0 <= k}\n",
    "    if len(val2txt) < len(unique_vals):\n",
    "        if all(float(v).is_integer() for v in unique_vals):\n",
    "            return \"int\"\n",
    "        return \"float\"\n",
    "    return \"nominal/ordinal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93a290",
   "metadata": {},
   "source": [
    "### Exploring the GSS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "306c1731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c516f2b8b08d43c7bb1db142c7298ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='variable', options=('fileversion', 'year', 'id', 'abany', 'abanyg'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntRangeSlider\n",
    "\n",
    "def inspect_column(variable: str, from_to: tuple[int, int]) -> None:\n",
    "    column = data[variable]\n",
    "    print(f\"question: {meta.column_names_to_labels.get(variable)} ({(ctype := infer_resp_type(variable, data, meta))})\")\n",
    "    if ctype == \"nominal/ordinal\":\n",
    "        val2txt = {k: v for k, v in meta.variable_value_labels.get(variable, {}).items() if 0 <= k}\n",
    "        print(f\"response labels:\\n  {'\\n  '.join(f'{k}: {v}' for k, v in val2txt.items())}\")\n",
    "    start, end = from_to\n",
    "    rows = column.iloc[start:end]\n",
    "    for idx, value in enumerate(rows.tolist()):\n",
    "        label = meta.variable_value_labels.get(variable, {}).get(value)\n",
    "        print(f\"{start + idx}: {value}{f', i.e., {label}' if label is not None else ''}\")\n",
    "\n",
    "interact(\n",
    "    inspect_column, \n",
    "    variable=data.columns, \n",
    "    from_to=IntRangeSlider(\n",
    "        min=0, \n",
    "        max=len(data), \n",
    "        step=1, \n",
    "        value=[0, 10], \n",
    "        description='rows'\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a104d59",
   "metadata": {},
   "source": [
    "## How to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9b7ab",
   "metadata": {},
   "source": [
    "### Which race is this persona?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "9038d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Mapping\n",
    "\n",
    "def race_from_gss(row: pd.Series, df: pd.DataFrame, meta: Any) -> str | None:\n",
    "    relevant = [\n",
    "        'raceacs1',\n",
    "        'raceacs2', \n",
    "        'raceacs3',\n",
    "        'raceacs4',\n",
    "        'raceacs5',\n",
    "        'raceacs6',\n",
    "        'raceacs7',\n",
    "        'raceacs8',\n",
    "        'raceacs9',\n",
    "        'raceacs10',\n",
    "        'raceacs14',\n",
    "        'raceacs16'\n",
    "    ]\n",
    "    races = df[relevant].columns.tolist()\n",
    "\n",
    "    stack: list[str] = []\n",
    "    for code in races:\n",
    "        label = meta.column_names_to_labels.get(code)\n",
    "        flag = meta.variable_value_labels.get(code, {}).get(row[code])\n",
    "        if flag == \"yes\":\n",
    "            stack.append(label)\n",
    "    \n",
    "    if not stack:\n",
    "        return None\n",
    "    elif len(stack) == 1:\n",
    "        return stack[0]\n",
    "    else:\n",
    "        return \", \".join(stack[:-1]) + f\", and {stack[-1]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef2052d",
   "metadata": {},
   "source": [
    "### Making persona descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a9fc087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def persona_desc(row: pd.Series, df: pd.DataFrame, meta: Any) -> Mapping[str, str]:\n",
    "    out =  {\n",
    "        \"age\": str(int(row[\"age\"])) if not pd.isna(row[\"age\"]) else None,\n",
    "        \"sex\": meta.variable_value_labels.get(\"sex\", {}).get(row[\"sex\"]),\n",
    "        \"race\": race_from_gss(row, df, meta),\n",
    "        \"religion\": meta.variable_value_labels.get(\"relig\", {}).get(row[\"relig\"]),\n",
    "        \"marital_status\": meta.variable_value_labels.get(\"marital\", {}).get(row[\"marital\"]),\n",
    "        \"employment_status\": meta.variable_value_labels.get(\"wrkstat\", {}).get(row[\"wrkstat\"]),\n",
    "        \"political_views\": meta.variable_value_labels.get(\"polviews\", {}).get(row[\"polviews\"]),\n",
    "        \"born_in_usa\": meta.variable_value_labels.get(\"born\", {}).get(row[\"born\"]),\n",
    "        \"education_level\": meta.variable_value_labels.get(\"educ\", {}).get(row[\"educ\"])\n",
    "    }\n",
    "    return {k: v for k, v in out.items() if v is not None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c1f0e2",
   "metadata": {},
   "source": [
    "### Exploring personas descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "933aabca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1030569aecea433c812621a107f318e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1654, description='idx', max=3308), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def inspect_persona(idx: int) -> None:\n",
    "    row = data.iloc[idx]\n",
    "    persona = persona_desc(row, data, meta)\n",
    "    print(f\"persona #{idx}:\")\n",
    "    for k, v in persona.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "interact(inspect_persona, idx=(0, len(data)-1, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06f76a",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "2495faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genagents.genagents import GenerativeAgent\n",
    "\n",
    "def respond(col: str, idx: int, df: pd.DataFrame, meta: Any) -> float | None:\n",
    "    row = df.iloc[idx]\n",
    "    agent = GenerativeAgent(); agent.update_scratch(persona_desc(row, df, meta))\n",
    "    question = meta.column_names_to_labels.get(col)\n",
    "    resp_type = infer_resp_type(col, df, meta)\n",
    "    labels = {k: v for k, v in meta.variable_value_labels.get(col, {}).items() if 0 <= k}\n",
    "    if resp_type == \"int\" or resp_type == \"float\":\n",
    "        min = float(df[col].dropna().min())\n",
    "        max = float(df[col].dropna().max())\n",
    "        resp_and_rationale = agent.numerical_resp({question: [min, max]}, float_resp=(resp_type == \"float\"))\n",
    "        if resp_and_rationale is not None and \"responses\" in resp_and_rationale:\n",
    "            resp = resp_and_rationale[\"responses\"]\n",
    "            if resp and len(resp) == 1:\n",
    "                return float(resp[0])\n",
    "    elif resp_type == \"nominal/ordinal\" and labels is not None:\n",
    "        resp_and_rationale = agent.categorical_resp({question: labels.values()})\n",
    "        if resp_and_rationale is not None and \"responses\" in resp_and_rationale:\n",
    "            resp = resp_and_rationale[\"responses\"]\n",
    "            if resp and len(resp) == 1:\n",
    "                for k, v in labels.items():\n",
    "                    if v == resp[0]:\n",
    "                        return k\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428215d9",
   "metadata": {},
   "source": [
    "### Exploring predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "66f347e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb4cd5ee42343179fbffe6a4e9faeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='col', options=('fileversion', 'year', 'id', 'abany', 'abanyg', 'ab…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "\n",
    "def inspect_response(col: str, idx: int) -> None:\n",
    "    column = data[col]\n",
    "    print(f\"question: {meta.column_names_to_labels.get(col)} ({(ctype := infer_resp_type(col, data, meta))})\")\n",
    "    if ctype == \"nominal/ordinal\":\n",
    "        val2txt = {k: v for k, v in meta.variable_value_labels.get(col, {}).items() if 0 <= k}\n",
    "        print(f\"response labels:\\n  {'\\n  '.join(f'{k}: {v}' for k, v in val2txt.items())}\")\n",
    "    resp = respond(col, idx, data, meta)\n",
    "    print(f\"response: {resp}{f', i.e., {val2txt.get(resp)}' if ctype == 'nominal/ordinal' and resp in val2txt else ''}\")\n",
    "    print(f\"target: {column.iloc[idx]}{f', i.e., {val2txt.get(column.iloc[idx])}' if ctype == 'nominal/ordinal' and column.iloc[idx] in val2txt else ''}\")\n",
    "\n",
    "interact_manual(inspect_response, col=list(data.columns), idx=(0, len(data)-1, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e338b2e",
   "metadata": {},
   "source": [
    "### Running simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "bbd19bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of columns to predict: 126\n",
      "# of columns also in GSS: 126\n"
     ]
    }
   ],
   "source": [
    "cols_to_predict = [\n",
    "#    'natspacy',\n",
    "#    'natenviy',\n",
    "#    'nathealy',\n",
    "#    'natcityy',\n",
    "#    'natdrugy',\n",
    "#    'nateducy',\n",
    "#    'natracey',\n",
    "#    'natarmsy',\n",
    "#    'nataidy',\n",
    "#    'natfarey',\n",
    "#    'natroad',\n",
    "#    'natsoc',\n",
    "#    'natspac',\n",
    "#    'natenvir',\n",
    "#    'natheal',\n",
    "#    'natcity',\n",
    "#   'natdrug',\n",
    "#    'nateduc',\n",
    "#    'natrace',\n",
    "#    'natarms',\n",
    "#    'nataid',\n",
    "#    'natfare',\n",
    "#    'natchld',\n",
    "#    'natsci',\n",
    "#    'natenrgy',\n",
    "    'prayer',\n",
    "#    'courts',\n",
    "    'discaffw',\n",
    "    'discaffm',\n",
    "    'fehire',\n",
    "    'fechld',\n",
    "    'fepresch',\n",
    "    'fefam',\n",
    "    'fepol',\n",
    "#    'reg16',\n",
    "    'mobile16',\n",
    "    'famdif16',\n",
    "    'incom16',\n",
    "    'dwelown16',\n",
    "    'paeduc',\n",
    "    'padeg',\n",
    "    'maeduc',\n",
    "    'madeg',\n",
    "    'mawrkgrw',\n",
    "    'marital',\n",
    "    'widowed',\n",
    "    'divorce',\n",
    "    'martype',\n",
    "    'posslqy',\n",
    "    'wrkstat',\n",
    "    'evwork',\n",
    "    'wrkgovt1',\n",
    "    'wrkgovt2',\n",
    "    'partfull',\n",
    "    'wksub1',\n",
    "    'wksup1',\n",
    "    'conarmy',\n",
    "    'conbus',\n",
    "    'conclerg',\n",
    "    'coneduc',\n",
    "    'confed',\n",
    "    'confinan',\n",
    "    'conjudge',\n",
    "    'conlabor',\n",
    "    'conlegis',\n",
    "    'conmedic',\n",
    "    'conpress',\n",
    "    'consci',\n",
    "    'contv',\n",
    "    'vetyears',\n",
    "    'joblose',\n",
    "#    'jobfind',\n",
    "    'happy',\n",
    "    'hapmar',\n",
    "    'satjob',\n",
    "    'speduc',\n",
    "    'spdeg',\n",
    "    'spwrksta',\n",
    "    'spfund',\n",
    "    'unemp',\n",
    "    'union1',\n",
    "    'spkathy',\n",
    "    'libathy',\n",
    "    'colath',\n",
    "    'spkracy',\n",
    "    'libracy',\n",
    "    'spkcomy',\n",
    "    'libcomy',\n",
    "    'colcomy',\n",
    "    'colrac',\n",
    "    'spkmslmy',\n",
    "    'libmslmy',\n",
    "    'cappun',\n",
    "    'polhitoky',\n",
    "    'polabusey',\n",
    "    'polattaky',\n",
    "    'grass',\n",
    "    'gunlaw',\n",
    "    'owngun',\n",
    "    'hunt1',\n",
    "    'class',\n",
    "    'satfin',\n",
    "    'finalter',\n",
    "    'finrela',\n",
    "    'race',\n",
    "#    'racdif1',\n",
    "#    'racdif2',\n",
    "#    'racdif3',\n",
    "#    'racdif4',\n",
    "#    'wlthwhts',\n",
    "#    'wlthblks',\n",
    "#    'wlthhsps',\n",
    "    'racwork',\n",
    "    'letin1a',\n",
    "    'getahead',\n",
    "    'parsol',\n",
    "    'kidssol',\n",
    "    'spanking',\n",
    "    'divlaw',\n",
    "    'sexeduc',\n",
    "    'pillok',\n",
    "    'xmarsex',\n",
    "    'homosex',\n",
    "    'discaff',\n",
    "#    'abdefect',\n",
    "#    'abnomore',\n",
    "#    'abhlth',\n",
    "#    'abpoor',\n",
    "#    'abrape',\n",
    "#    'absingle',\n",
    "#    'abany',\n",
    "    'letdie1',\n",
    "#    'suicide1',\n",
    "#    'suicide2',\n",
    "#    'suicide4',\n",
    "    'pornlaw',\n",
    "    'fair',\n",
    "    'helpful',\n",
    "    'trust',\n",
    "    'tax',\n",
    "    'vote16',\n",
    "    'pres16',\n",
    "    'if16who',\n",
    "    'polviews',\n",
    "    'partyid',\n",
    "    'news',\n",
    "    'relig',\n",
    "    'relig16',\n",
    "    'attend',\n",
    "    'pray',\n",
    "    'postlife',\n",
    "    'bible',\n",
    "    'reborn',\n",
    "    'relpersn',\n",
    "    'sprtprsn',\n",
    "    'born',\n",
    "    'granborn',\n",
    "#    'uscitzn',\n",
    "    'educ',\n",
    "    'degree',\n",
    "    'income',\n",
    "    'visitors',\n",
    "    'dwelown',\n",
    "    'othlang',\n",
    "    'sex',\n",
    "    'hispanic',\n",
    "    'health',\n",
    "    'compuse',\n",
    "    'webmob',\n",
    "    'xmovie',\n",
    "    'life',\n",
    "    'richwork'\n",
    "]\n",
    "\n",
    "print(f\"# of columns to predict: {len(cols_to_predict)}\")\n",
    "print(f\"# of columns also in GSS: {len({k for k in cols_to_predict if k in data})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "df9647cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def respond_all(cols: Iterable[str], df: pd.DataFrame, meta: Any, num_workers: int = 4, skip_nan: bool = False) -> pd.DataFrame:\n",
    "    pred = df.copy()\n",
    "    tasks = [(col, idx) for idx in range(len(df)) for col in cols if col in df.columns and (not skip_nan or not pd.isna(df.at[idx, col]))]\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as exe:\n",
    "        futures = {exe.submit(respond, col, idx, df, meta): (col, idx) for col, idx in tasks}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"{len(df)} respondents x {len(cols)} questions\"):\n",
    "            col, idx = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    pred.at[idx, col] = result\n",
    "            except Exception as err:\n",
    "                print(f\"[ERROR] in col {col}, idx {idx}: {err}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90817ede",
   "metadata": {},
   "source": [
    "#### Random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "46347a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def respond_random(col: str, idx: int, df: pd.DataFrame, meta: Any) -> float | None:\n",
    "    resp_type = infer_resp_type(col, df, meta)\n",
    "    labels = {k: v for k, v in meta.variable_value_labels.get(col, {}).items() if 0 <= k}\n",
    "    rng = np.random.default_rng()\n",
    "    vals = df[col].dropna()\n",
    "    if resp_type == \"int\":\n",
    "        if len(vals) == 0:\n",
    "            return None\n",
    "        return int(rng.integers(int(vals.min()), int(vals.max()) + 1))\n",
    "    elif resp_type == \"float\":\n",
    "        if len(vals) == 0:\n",
    "            return None\n",
    "        return float(rng.uniform(vals.min(), vals.max()))\n",
    "    elif resp_type == \"nominal/ordinal\" and labels:\n",
    "        if labels:\n",
    "            return rng.choice(list(labels.keys()))\n",
    "    return None\n",
    "\n",
    "def respond_all_random(cols: Iterable[str], df: pd.DataFrame, meta: Any, num_workers: int = 4, skip_nan: bool = False) -> pd.DataFrame:\n",
    "    pred = df.copy()\n",
    "    tasks = [(col, idx) for idx in range(len(df)) for col in cols if col in df.columns and (not skip_nan or not pd.isna(df.at[idx, col]))]\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as exe:\n",
    "        futures = {exe.submit(respond_random, col, idx, df, meta): (col, idx) for col, idx in tasks}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"{len(df)} respondents x {len(cols)} questions (baseline)\"):\n",
    "            col, idx = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    pred.at[idx, col] = result\n",
    "            except Exception as err:\n",
    "                print(f\"[ERROR] in col {col}, idx {idx}: {err}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4bd0a809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7776050fdb44b4931f59f8372002b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='num_people', max=3309, min=1), IntSlider(value=101, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ipywidgets import IntSlider\n",
    "\n",
    "true: pd.DataFrame | None = None\n",
    "pred: pd.DataFrame | None = None\n",
    "base: pd.DataFrame | None = None\n",
    "\n",
    "def run_response_simulation(num_people: int, num_workers: int, skip_nan: bool) -> None:\n",
    "    global pred, true, base\n",
    "    true, _ = from_gss(\"./datasets/2024_spss/2024/GSS2024.sav\", n_sample=num_people)\n",
    "    pred = respond_all(cols_to_predict, true, meta, num_workers=num_workers, skip_nan=skip_nan)\n",
    "    base = respond_all_random(cols_to_predict, true, meta, num_workers=num_workers, skip_nan=skip_nan)\n",
    "    true.to_pickle(f\"./saved_tests/gss{num_people}_true.pkl\")\n",
    "    pred.to_pickle(f\"./saved_tests/gss{num_people}_pred.pkl\")\n",
    "    base.to_pickle(f\"./saved_tests/gss{num_people}_base.pkl\")\n",
    "\n",
    "interact_manual(run_response_simulation, num_people=IntSlider(min=1, max=len(data), step=1, value=5), num_workers=IntSlider(min=1, max=7 * max(32, os.cpu_count() or 1), step=1, value=101), skip_nan=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcde9ee",
   "metadata": {},
   "source": [
    "## Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc6e1b",
   "metadata": {},
   "source": [
    "### Score and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "fb90be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as f1_fn\n",
    "\n",
    "def acc_score(pred: pd.DataFrame, true: pd.DataFrame) -> pd.Series:\n",
    "    mask = ~true.isna()\n",
    "    correct = (pred == true) & mask\n",
    "    return correct.sum() / mask.sum()\n",
    "\n",
    "def mae_score(pred: pd.DataFrame, true: pd.DataFrame) -> pd.Series:\n",
    "    mask = ~true.isna()\n",
    "    return (pred - true).abs().where(mask).apply(lambda col: col.mean())\n",
    "\n",
    "def f1_score(pred: pd.DataFrame, true: pd.DataFrame) -> pd.Series:\n",
    "    mask = ~true.isna()\n",
    "    def f1_col(col):\n",
    "        y_true = true[col.name][mask[col.name]]\n",
    "        y_pred = pred[col.name][mask[col.name]]\n",
    "        if y_true.nunique() < 2 or len(y_true) == 0:\n",
    "            return float('nan')\n",
    "        try:\n",
    "            return f1_fn(y_true, y_pred, average='macro')\n",
    "        except ValueError:\n",
    "            return float('nan')\n",
    "    return pred.apply(f1_col)\n",
    "\n",
    "def corr_score(pred: pd.DataFrame, true: pd.DataFrame) -> pd.Series:\n",
    "    mask = ~true.isna()\n",
    "    def corr_col(col):\n",
    "        x = pred[col.name][mask[col.name]]\n",
    "        y = true[col.name][mask[col.name]]\n",
    "        if len(x) < 2:\n",
    "            return float('nan')\n",
    "        if x.std() == 0 or y.std() == 0:\n",
    "            return float('nan')\n",
    "        try:\n",
    "            return x.corr(y)\n",
    "        except Exception:\n",
    "            return float('nan')\n",
    "    return pred.apply(corr_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf6712",
   "metadata": {},
   "source": [
    "### Load data to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "cbc0e976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d525b80d4ec64acaa7a8a2160fb8efa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='num_people', max=3309, min=1), Button(description='Run I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\")\n",
    "\n",
    "score_fns = OrderedDict([\n",
    "    (\"acc\", acc_score),\n",
    "    (\"f1\", f1_score),\n",
    "    (\"mae\", mae_score),\n",
    "    (\"corr\", corr_score)\n",
    "])\n",
    "scores: Mapping[str, pd.Series] | None = None\n",
    "baselines: Mapping[str, pd.Series] | None = None\n",
    "\n",
    "def load_results(num_people: int) -> None:\n",
    "    if not os.path.exists(f\"./saved_tests/gss{num_people}_true.pkl\") or not os.path.exists(f\"./saved_tests/gss{num_people}_pred.pkl\"):\n",
    "        print(f\"No saved results with {num_people}.\")\n",
    "        return\n",
    "    global true, pred, base, scores, baselines\n",
    "    true = pd.read_pickle(f\"./saved_tests/gss{num_people}_true.pkl\")\n",
    "    pred = pd.read_pickle(f\"./saved_tests/gss{num_people}_pred.pkl\")\n",
    "    base = pd.read_pickle(f\"./saved_tests/gss{num_people}_base.pkl\")\n",
    "    scores = {k: fn(pred, true) for k, fn in score_fns.items()}\n",
    "    baselines = {k: fn(base, true) for k, fn in score_fns.items()}\n",
    "\n",
    "interact_manual(load_results, num_people=IntSlider(min=1, max=len(data), step=1, value=5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb3801",
   "metadata": {},
   "source": [
    "### Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "bb3070c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a8612588544d2e81a558548f589b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='col', options=('prayer', 'discaffw', 'discaffm', 'fehire', 'fechld…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def inspect_column_scores(col: str) -> None:\n",
    "    if scores is not None and baselines is not None:\n",
    "        print(f\"for {col}:\")\n",
    "        if infer_resp_type(col, data, meta) in [\"int\", \"float\"]:\n",
    "            print(f\"  mae: {scores['mae'][col]} (baseline: {baselines['mae'][col]})\")\n",
    "            print(f\"  corr: {scores['corr'][col]} (baseline: {baselines['corr'][col]})\")\n",
    "        elif infer_resp_type(col, data, meta) == \"nominal/ordinal\":\n",
    "            print(f\"  acc: {scores['acc'][col]} (baseline: {baselines['acc'][col]})\")\n",
    "            print(f\"  f1: {scores['f1'][col]} (baseline: {baselines['f1'][col]})\")\n",
    "        print(f\"overall:\")\n",
    "        for metric, score in scores.items():\n",
    "            overall_score = score.mean()\n",
    "            print(f\"  {metric}: {overall_score} (baseline: {baselines[metric].mean()})\")\n",
    "    else:\n",
    "        print(\"No test data loaded.\")\n",
    "\n",
    "interact(inspect_column_scores, col=cols_to_predict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "0c785ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d600e377a4744d1a0ba5e55e73ab552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='metric', options=('acc', 'f1', 'mae', 'corr'), value='acc'), IntRa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from colorama import Fore, Style\n",
    "\n",
    "color_maps = (\n",
    "    (\"f1\", (0.8, 1.0), Fore.GREEN),\n",
    "    (\"f1\", (0.6, 0.8), Fore.YELLOW),\n",
    "    (\"f1\", (0.0, 0.6), Fore.RED),\n",
    "    (\"acc\", (0.8, 1.0), Fore.GREEN),\n",
    "    (\"acc\", (0.6, 0.8), Fore.YELLOW),\n",
    "    (\"acc\", (0.0, 0.6), Fore.RED),\n",
    "    (\"mae\", (0.0, 1.0), Fore.GREEN),\n",
    "    (\"mae\", (1.0, 2.0), Fore.YELLOW),\n",
    "    (\"mae\", (2.0, float('inf')), Fore.RED),\n",
    "    (\"corr\", (0.7, 1.0), Fore.GREEN),\n",
    "    (\"corr\", (0.3, 0.7), Fore.YELLOW),\n",
    "    (\"corr\", (-1.0, 0.3), Fore.RED)\n",
    ")\n",
    "\n",
    "def pick_color(metric: str, value: float) -> str:\n",
    "    for name, (low, high), color in color_maps:\n",
    "        if name == metric and low <= value <= high:\n",
    "            return color\n",
    "    return \"\"\n",
    "\n",
    "def print_ranked(metric: str, from_to: tuple[int, int], minimize: bool, of_type: str) -> None:\n",
    "    if scores is None or baselines is None:\n",
    "        print(\"No test data loaded.\")\n",
    "        return\n",
    "    filtered_cols = [col for col in cols_to_predict if infer_resp_type(col, data, meta) == of_type]\n",
    "    if not filtered_cols:\n",
    "        print(f\"No columns of type {of_type}.\")\n",
    "        return\n",
    "    pred_scores = scores.get(metric)[filtered_cols]\n",
    "    base_scores = baselines.get(metric)[filtered_cols]\n",
    "    ranked = (pred_scores - base_scores).sort_values(ascending=minimize)\n",
    "    start, end = from_to\n",
    "    print(\" \".join(f\"{color}■{Style.RESET_ALL} {len([col for col in cols_to_predict if pick_color(metric, scores[metric][col]) == color]) / len(cols_to_predict):.1%}\" for name, _, color in color_maps if name == metric), end=\"\\n\\n\")\n",
    "    for idx, (col, _) in enumerate(ranked.iloc[start:end].items(), start=start):\n",
    "        print(f\"{idx + 1}. {col}: {pick_color(metric, pred_scores[col])}{pred_scores[col]}{Style.RESET_ALL} (baseline: {pick_color(metric, base_scores[col])}{base_scores[col]}{Style.RESET_ALL})\")\n",
    "\n",
    "interact(\n",
    "    print_ranked, \n",
    "    metric=score_fns.keys(), \n",
    "    from_to=IntRangeSlider(\n",
    "        min=0,\n",
    "        max=len(cols_to_predict),\n",
    "        step=1,\n",
    "        value=(0, 5)\n",
    "    ),\n",
    "    of_type=[\"nominal/ordinal\", \"int\", \"float\"],\n",
    "    minimize=False\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6e588",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de266bd",
   "metadata": {},
   "source": [
    "1. So few respondents selected \"yes\" under \"widowed\" that sampling only 50 respondents had all answering \"no\". Hence, accuracy and F1 scores fail. They need at least to active classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
