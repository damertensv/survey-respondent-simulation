{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46e673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Any, TypedDict\n",
    "from ipywidgets import interact, interact_manual\n",
    "from collections import OrderedDict\n",
    "from collections.abc import Mapping\n",
    "from tqdm import tqdm\n",
    "from colorama import Fore, Style\n",
    "from enum import Enum\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class VarType(Enum):\n",
    "    INTEGER = \"integer\"\n",
    "    CONTINUOUS = \"continuous\"\n",
    "    CATEGORICAL = \"categorical\"\n",
    "\n",
    "\n",
    "class VarData(TypedDict):\n",
    "    question: str | None\n",
    "    resp_type: VarType\n",
    "    resp_list: list[float | None]\n",
    "    resp_to_text: OrderedDict[int, str] | tuple[int | float, int | float] | None\n",
    "    min_max: tuple[int | float, int | float] | None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c2740",
   "metadata": {},
   "source": [
    "## Loading GSS *Simulation* Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d88edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_people = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b5b4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "def load_gss_data(filename_prefix: str = \"gss_analysis\"):\n",
    "    \"\"\"Load previously saved GSS data.\"\"\"\n",
    "    save_dir = Path(\"gss_saved_data\")\n",
    "    \n",
    "    # Load predicted data\n",
    "    pred_path = save_dir / f\"{filename_prefix}_pred.pkl\"\n",
    "    with open(pred_path, 'rb') as f:\n",
    "        gss_pred = pickle.load(f)\n",
    "    \n",
    "    # Load actual data\n",
    "    data_path = save_dir / f\"{filename_prefix}_data.pkl\"\n",
    "    with open(data_path, 'rb') as f:\n",
    "        gss_data = pickle.load(f)\n",
    "    \n",
    "    return gss_pred, gss_data\n",
    "\n",
    "# Load later for analysis\n",
    "gss_pred, gss_data = load_gss_data(filename_prefix=f\"gss_2024_{num_people}_people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89d221",
   "metadata": {},
   "source": [
    "## Basic Inspect GSS Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "382c2c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3cbc6434c24f87a7b950c3a2ab0e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, description='idx', max=1000), Dropdown(description='code', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def inspect_pred(idx: int, code: str) -> None:\n",
    "    print(f\"Question: {gss_data[code]['question']}\")\n",
    "    print(f\"Target: {gss_data[code]['resp_list'][idx]}, i.e., {gss_data[code]['resp_to_text'].get(gss_data[code]['resp_list'][idx], 'N/A')} ({gss_data[code]['resp_type']})\")\n",
    "    print(f\"Pred: {gss_pred[code]['resp_list'][idx]}, i.e., {gss_pred[code]['resp_to_text'].get(gss_pred[code]['resp_list'][idx], 'N/A')} ({gss_pred[code]['resp_type']})\")\n",
    "\n",
    "interact(inspect_pred, idx=(0, len(next(iter(gss_data.values()))[\"resp_list\"]), 1), code=gss_data.keys());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b33b9c",
   "metadata": {},
   "source": [
    "## In-Depth Comparison of GSS Simulation Results vs GSS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b59e2746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of vars to predict also in GSS: 100%\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\n",
    "    'natspacy',\n",
    "    'natenviy',\n",
    "    'nathealy',\n",
    "    'natcityy',\n",
    "    'natdrugy',\n",
    "    'nateducy',\n",
    "    'natracey',\n",
    "    'natarmsy',\n",
    "    'nataidy',\n",
    "    'natfarey',\n",
    "    'natroad',\n",
    "    'natsoc',\n",
    "    'natspac',\n",
    "    'natenvir',\n",
    "    'natheal',\n",
    "    'natcity',\n",
    "    'natdrug',\n",
    "    'nateduc',\n",
    "    'natrace',\n",
    "    'natarms',\n",
    "    'nataid',\n",
    "    'natfare',\n",
    "    'natchld',\n",
    "    'natsci',\n",
    "    'natenrgy',\n",
    "    'prayer',\n",
    "    'courts',\n",
    "    'discaffw',\n",
    "    'discaffm',\n",
    "    'fehire',\n",
    "    'fechld',\n",
    "    'fepresch',\n",
    "    'fefam',\n",
    "    'fepol',\n",
    "    'reg16',\n",
    "    'mobile16',\n",
    "    'famdif16',\n",
    "    'incom16',\n",
    "    'dwelown16',\n",
    "    'paeduc',\n",
    "    'padeg',\n",
    "    'maeduc',\n",
    "    'madeg',\n",
    "    'mawrkgrw',\n",
    "    'marital',\n",
    "    'widowed',\n",
    "    'divorce',\n",
    "    'martype',\n",
    "    'posslqy',\n",
    "    'wrkstat',\n",
    "    'evwork',\n",
    "    'wrkgovt1',\n",
    "    'wrkgovt2',\n",
    "    'partfull',\n",
    "    'wksub1',\n",
    "    'wksup1',\n",
    "    'conarmy',\n",
    "    'conbus',\n",
    "    'conclerg',\n",
    "    'coneduc',\n",
    "    'confed',\n",
    "    'confinan',\n",
    "    'conjudge',\n",
    "    'conlabor',\n",
    "    'conlegis',\n",
    "    'conmedic',\n",
    "    'conpress',\n",
    "    'consci',\n",
    "    'contv',\n",
    "    'vetyears',\n",
    "    'joblose',\n",
    "    'jobfind',\n",
    "    'happy',\n",
    "    'hapmar',\n",
    "    'satjob',\n",
    "    'speduc',\n",
    "    'spdeg',\n",
    "    'spwrksta',\n",
    "    'spfund',\n",
    "    'unemp',\n",
    "    'union1',\n",
    "    'spkathy',\n",
    "    'libathy',\n",
    "    'colath',\n",
    "    'spkracy',\n",
    "    'libracy',\n",
    "    'spkcomy',\n",
    "    'libcomy',\n",
    "    'colcomy',\n",
    "    'colrac',\n",
    "    'spkmslmy',\n",
    "    'libmslmy',\n",
    "    'cappun',\n",
    "    'polhitoky',\n",
    "    'polabusey',\n",
    "    'polattaky',\n",
    "    'grass',\n",
    "    'gunlaw',\n",
    "    'owngun',\n",
    "    'hunt1',\n",
    "    'class',\n",
    "    'satfin',\n",
    "    'finalter',\n",
    "    'finrela',\n",
    "    'race',\n",
    "    'racdif1',\n",
    "    'racdif2',\n",
    "    'racdif3',\n",
    "    'racdif4',\n",
    "    'wlthwhts',\n",
    "    'wlthblks',\n",
    "    'wlthhsps',\n",
    "    'racwork',\n",
    "    'letin1a',\n",
    "    'getahead',\n",
    "    'parsol',\n",
    "    'kidssol',\n",
    "    'spanking',\n",
    "    'divlaw',\n",
    "    'sexeduc',\n",
    "    'pillok',\n",
    "    'xmarsex',\n",
    "    'homosex',\n",
    "    'discaff',\n",
    "    'abdefect',\n",
    "    'abnomore',\n",
    "    'abhlth',\n",
    "    'abpoor',\n",
    "    'abrape',\n",
    "    'absingle',\n",
    "    'abany',\n",
    "    'letdie1',\n",
    "    'suicide1',\n",
    "    'suicide2',\n",
    "    'suicide4',\n",
    "    'pornlaw',\n",
    "    'fair',\n",
    "    'helpful',\n",
    "    'trust',\n",
    "    'tax',\n",
    "    'vote16',\n",
    "    'pres16',\n",
    "    'if16who',\n",
    "    'polviews',\n",
    "    'partyid',\n",
    "    'news',\n",
    "    'relig',\n",
    "    'relig16',\n",
    "    'attend',\n",
    "    'pray',\n",
    "    'postlife',\n",
    "    'bible',\n",
    "    'reborn',\n",
    "    'relpersn',\n",
    "    'sprtprsn',\n",
    "    'born',\n",
    "    'granborn',\n",
    "    'uscitzn',\n",
    "    'educ',\n",
    "    'degree',\n",
    "    'income',\n",
    "    'visitors',\n",
    "    'dwelown',\n",
    "    'othlang',\n",
    "    'sex',\n",
    "    'hispanic',\n",
    "    'health',\n",
    "    'compuse',\n",
    "    'webmob',\n",
    "    'xmovie',\n",
    "    'life',\n",
    "    'richwork'\n",
    "]\n",
    "\n",
    "print(f\"% of vars to predict also in GSS: {int(100. * len({k for k in to_predict if k in gss_data}) / len(to_predict))}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f38cbcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CATEGORICAL VARIABLES\n",
      "================================================================================\n",
      "             natspacy  natenviy  nathealy  natcityy  natdrugy  nateducy  \\\n",
      "accuracy       0.4908    0.4000    0.1947    0.3836    0.4136    0.2212   \n",
      "correlation    0.0861    0.3396    0.0482    0.1713    0.1620    0.1838   \n",
      "\n",
      "             natracey  natarmsy  nataidy  natfarey  natroad  natsoc  natspac  \\\n",
      "accuracy       0.5789    0.4279   0.4009     0.473   0.3991  0.3925   0.4741   \n",
      "correlation    0.3803    0.1592   0.1760     0.371   0.0277 -0.0191   0.0706   \n",
      "\n",
      "             natenvir  natheal  natcity  natdrug  nateduc  natrace  natarms  \\\n",
      "accuracy       0.4634   0.3933   0.4286   0.4274   0.5145   0.5022   0.4421   \n",
      "correlation    0.3972   0.2504   0.2469   0.1548   0.1863   0.3600   0.3101   \n",
      "\n",
      "             nataid  natfare  natchld  natsci  natenrgy  prayer  courts  \\\n",
      "accuracy     0.4093   0.4430   0.4728  0.4447    0.4677  0.4215  0.4175   \n",
      "correlation  0.1612   0.3552   0.1986  0.1276    0.3309 -0.1685 -0.0628   \n",
      "\n",
      "             discaffw  discaffm  fehire  fechld  fepresch   fefam   fepol  \\\n",
      "accuracy       0.4876    0.2993  0.3355  0.3639    0.4649  0.4852  0.7797   \n",
      "correlation    0.1549   -0.0133  0.2086  0.1534    0.2375  0.3635  0.1550   \n",
      "\n",
      "              reg16  mobile16  famdif16  incom16  dwelown16  paeduc   padeg  \\\n",
      "accuracy     0.3688    0.4708    0.1268   0.4192     0.6890  0.3569  0.3589   \n",
      "correlation  0.3394    0.3417   -0.2169   0.1133     0.1964  0.3286  0.2848   \n",
      "\n",
      "             maeduc   madeg  mawrkgrw  marital  widowed  divorce  martype  \\\n",
      "accuracy     0.3455  0.3812    0.6918      1.0   0.9386   0.7069    0.630   \n",
      "correlation  0.3660  0.3355    0.1248      1.0  -0.0303  -0.0271    0.114   \n",
      "\n",
      "             posslqy  wrkstat  evwork  wrkgovt1  wrkgovt2  partfull  wksub1  \\\n",
      "accuracy      0.8438   0.9957  0.8978    0.7835    0.5583    0.8774  0.7939   \n",
      "correlation   0.9140   0.9975  0.3382       NaN    0.0271    0.6884  0.1019   \n",
      "\n",
      "             wksup1  conarmy  conbus  conclerg  coneduc  confed  confinan  \\\n",
      "accuracy     0.6042   0.4548  0.5806    0.5392   0.5375  0.4098    0.5502   \n",
      "correlation  0.1694   0.0699  0.1758    0.2470   0.0442 -0.0449    0.0136   \n",
      "\n",
      "             conjudge  conlabor  conlegis  conmedic  conpress  consci   contv  \\\n",
      "accuracy       0.3987    0.5935    0.4212    0.4857    0.5327  0.5863  0.5146   \n",
      "correlation    0.1411    0.1186   -0.0137    0.0023    0.1738  0.3046 -0.0037   \n",
      "\n",
      "             vetyears  joblose  jobfind   happy  hapmar  satjob  speduc  \\\n",
      "accuracy       0.8889   0.5028   0.4213  0.5847  0.4384  0.3976  0.2772   \n",
      "correlation    0.3137   0.0327   0.1059  0.0218  0.0692  0.1026  0.3768   \n",
      "\n",
      "              spdeg  spwrksta  spfund   unemp  union1  spkathy  libathy  \\\n",
      "accuracy     0.3251    0.6535  0.5737  0.6592  0.8889   0.7032   0.6513   \n",
      "correlation  0.2707    0.3770  0.3308  0.3242     NaN  -0.0348   0.1704   \n",
      "\n",
      "             colath  spkracy  libracy  spkcomy  libcomy  colcomy  colrac  \\\n",
      "accuracy     0.6115   0.5350   0.6076   0.6410   0.7152   0.6376  0.6125   \n",
      "correlation  0.1206   0.0907   0.1274   0.0864   0.0755   0.1601  0.0299   \n",
      "\n",
      "             spkmslmy  libmslmy  cappun  polhitoky  polabusey  polattaky  \\\n",
      "accuracy       0.5633    0.6013  0.5776     0.4932     0.3077     0.3973   \n",
      "correlation    0.0341    0.1982  0.1755     0.0859    -0.0124     0.0672   \n",
      "\n",
      "              grass  gunlaw  owngun   hunt1   class  satfin  finalter  \\\n",
      "accuracy     0.6195  0.7290  0.6178  0.8318  0.5236  0.4375    0.4145   \n",
      "correlation  0.2354  0.2889  0.1850  0.0281  0.2931  0.1466    0.0543   \n",
      "\n",
      "             finrela    race  racdif1  racdif2  racdif3  racdif4  letin1a  \\\n",
      "accuracy      0.4209  0.9657   0.6779   0.5325   0.5347   0.5625   0.2894   \n",
      "correlation   0.2585  0.9323   0.3748   0.0992   0.0933   0.0902   0.2835   \n",
      "\n",
      "             getahead  parsol  kidssol  spanking  divlaw  sexeduc  pillok  \\\n",
      "accuracy       0.3643  0.3195   0.2500    0.4178  0.3145   0.4027  0.4189   \n",
      "correlation   -0.0592  0.1846   0.1256    0.2739  0.1199   0.1471  0.3929   \n",
      "\n",
      "             xmarsex  homosex  discaff  abdefect  abnomore  abhlth  abpoor  \\\n",
      "accuracy      0.5063   0.5738   0.3982    0.5200    0.5268  0.8465  0.5047   \n",
      "correlation   0.2171   0.4252   0.2036   -0.0338    0.0008  0.0807  0.0152   \n",
      "\n",
      "             abrape  absingle   abany  letdie1  suicide1  suicide2  suicide4  \\\n",
      "accuracy     0.8198    0.5364  0.7115   0.6933     0.568    0.8667    0.7650   \n",
      "correlation  0.3219    0.0632  0.4068   0.3241     0.197       NaN    0.2503   \n",
      "\n",
      "             pornlaw    fair  helpful   trust     tax  vote16  pres16  \\\n",
      "accuracy      0.6635  0.1393   0.1583  0.2083  0.3648  0.7071  0.7663   \n",
      "correlation   0.1411 -0.1308   0.1769  0.2182  0.1140  0.6223  0.4238   \n",
      "\n",
      "             if16who  polviews  partyid    news  relig  relig16  attend  \\\n",
      "accuracy      0.4276       1.0   0.3498  0.1505    1.0   0.6957  0.2951   \n",
      "correlation   0.2016       1.0   0.5841  0.1384    1.0   0.4239  0.4496   \n",
      "\n",
      "               pray  postlife   bible  reborn  relpersn  sprtprsn  born  \\\n",
      "accuracy     0.3077    0.8090  0.5440  0.7155    0.5108    0.3824   1.0   \n",
      "correlation  0.5270    0.2582  0.3863  0.3889    0.5840    0.3600   1.0   \n",
      "\n",
      "             granborn  uscitzn  educ  degree  income  visitors  dwelown  \\\n",
      "accuracy       0.7264   0.5926   1.0  0.7011  0.0825    0.0169   0.7252   \n",
      "correlation    0.7434   0.1581   1.0  0.8743  0.2396   -0.0608   0.4756   \n",
      "\n",
      "             othlang  sex  hispanic  health  compuse  webmob  xmovie    life  \\\n",
      "accuracy      0.7458  1.0    0.8664  0.5359   0.8201  0.5366  0.6747  0.4299   \n",
      "correlation   0.3873  1.0    0.5467  0.0092   0.1838  0.0248  0.3950 -0.0167   \n",
      "\n",
      "             richwork  \n",
      "accuracy       0.5758  \n",
      "correlation   -0.0213  \n",
      "\n",
      "----------------------------------------\n",
      "Summary (Categorical):\n",
      "  accuracy     - Mean: 0.5425, Median: 0.5218, Std: 0.2030, Min: 0.0169, Max: 1.0000\n",
      "  correlation  - Mean: 0.2395, Median: 0.1769, Std: 0.2484, Min: -0.2169, Max: 1.0000\n",
      "\n",
      "================================================================================\n",
      "NUMERICAL VARIABLES\n",
      "================================================================================\n",
      "             wlthwhts  wlthblks  wlthhsps\n",
      "correlation   -0.0761    -0.126    0.0408\n",
      "mae            1.0405     0.953    1.1333\n",
      "\n",
      "----------------------------------------\n",
      "Summary (Numerical):\n",
      "  correlation  - Mean: -0.0538, Median: -0.0761, Std: 0.0857, Min: -0.1260, Max: 0.0408\n",
      "  mae          - Mean: 1.0423, Median: 1.0405, Std: 0.0902, Min: 0.9530, Max: 1.1333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "def compare(gss_pred: OrderedDict[str, VarData], \n",
    "            gss_data: OrderedDict[str, VarData]) -> dict[str, dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Compare predicted GSS responses with actual responses using metrics from the paper.\n",
    "    \n",
    "    Categorical variables: accuracy and correlation\n",
    "    Numerical variables: MAE and correlation\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for var_code in to_predict:\n",
    "        if var_code not in gss_pred or var_code not in gss_data:\n",
    "            continue\n",
    "            \n",
    "        pred_data = gss_pred[var_code]\n",
    "        true_data = gss_data[var_code]\n",
    "        \n",
    "        # Get response lists and convert to numpy arrays\n",
    "        pred_array = np.array([float(x) if x is not None else np.nan for x in pred_data[\"resp_list\"]])\n",
    "        true_array = np.array([float(x) if x is not None else np.nan for x in true_data[\"resp_list\"]])\n",
    "        \n",
    "        # Filter out invalid pairs (where either is NaN)\n",
    "        valid_mask = ~(np.isnan(pred_array) | np.isnan(true_array))\n",
    "        if not np.any(valid_mask):\n",
    "            continue\n",
    "            \n",
    "        pred_valid = pred_array[valid_mask]\n",
    "        true_valid = true_array[valid_mask]\n",
    "        \n",
    "        metrics = {}\n",
    "        resp_type = pred_data[\"resp_type\"]\n",
    "        \n",
    "        if resp_type == VarType.CATEGORICAL:\n",
    "            # Categorical variables: accuracy and correlation\n",
    "            pred_int = pred_valid.astype(int)\n",
    "            true_int = true_valid.astype(int)\n",
    "            \n",
    "            # Accuracy\n",
    "            metrics[\"accuracy\"] = accuracy_score(true_int, pred_int)\n",
    "            \n",
    "            # Correlation (if possible)\n",
    "            if len(np.unique(true_int)) > 1 and len(np.unique(pred_int)) > 1:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    metrics[\"correlation\"] = np.corrcoef(true_int, pred_int)[0, 1]\n",
    "            else:\n",
    "                metrics[\"correlation\"] = np.nan\n",
    "                \n",
    "        else:  # INTEGER or CONTINUOUS\n",
    "            # Numerical variables: MAE and correlation\n",
    "            \n",
    "            # Mean Absolute Error\n",
    "            metrics[\"mae\"] = mean_absolute_error(true_valid, pred_valid)\n",
    "            \n",
    "            # Correlation (if possible)\n",
    "            if len(np.unique(true_valid)) > 1 and len(np.unique(pred_valid)) > 1:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    metrics[\"correlation\"] = np.corrcoef(true_valid, pred_valid)[0, 1]\n",
    "            else:\n",
    "                metrics[\"correlation\"] = np.nan\n",
    "        \n",
    "        results[var_code] = metrics\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def display_results_table(results: dict[str, dict[str, float]], \n",
    "                         decimal_places: int = 4,\n",
    "                         show_summary: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Display comparison results in a clean table format.\n",
    "    \n",
    "    Args:\n",
    "        results: Output from compare() function\n",
    "        decimal_places: Number of decimal places to show\n",
    "        show_summary: Whether to print summary statistics\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with the results\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to display\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Collect all metrics and create DataFrame\n",
    "    all_metrics = set()\n",
    "    for metrics in results.values():\n",
    "        all_metrics.update(metrics.keys())\n",
    "    all_metrics = sorted(list(all_metrics))\n",
    "    \n",
    "    # Build DataFrame\n",
    "    df_data = {}\n",
    "    for var_code, metrics in results.items():\n",
    "        df_data[var_code] = [metrics.get(metric, np.nan) for metric in all_metrics]\n",
    "    \n",
    "    df = pd.DataFrame(df_data, index=all_metrics)\n",
    "    \n",
    "    # Separate categorical and numerical variables based on metrics\n",
    "    cat_vars = [col for col in df.columns if not np.isnan(df.loc['accuracy', col]) if 'accuracy' in df.index]\n",
    "    num_vars = [col for col in df.columns if not np.isnan(df.loc['mae', col]) if 'mae' in df.index]\n",
    "    \n",
    "    # Format display\n",
    "    pd.set_option('display.precision', decimal_places)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    \n",
    "    # Print categorical variables\n",
    "    if cat_vars:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CATEGORICAL VARIABLES\")\n",
    "        print(\"=\"*80)\n",
    "        df_cat = df[cat_vars].dropna(how='all')\n",
    "        print(df_cat.round(decimal_places))\n",
    "        \n",
    "        if show_summary:\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"Summary (Categorical):\")\n",
    "            for metric in df_cat.index:\n",
    "                values = df_cat.loc[metric].dropna()\n",
    "                if len(values) > 0:\n",
    "                    print(f\"  {metric:12s} - Mean: {values.mean():.4f}, Median: {values.median():.4f}, Std: {values.std():.4f}, \"\n",
    "                          f\"Min: {values.min():.4f}, Max: {values.max():.4f}\")\n",
    "    \n",
    "    # Print numerical variables\n",
    "    if num_vars:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"NUMERICAL VARIABLES\")\n",
    "        print(\"=\"*80)\n",
    "        df_num = df[num_vars].dropna(how='all')\n",
    "        print(df_num.round(decimal_places))\n",
    "        \n",
    "        if show_summary:\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"Summary (Numerical):\")\n",
    "            for metric in df_num.index:\n",
    "                values = df_num.loc[metric].dropna()\n",
    "                if len(values) > 0:\n",
    "                    print(f\"  {metric:12s} - Mean: {values.mean():.4f}, Median: {values.median():.4f}, Std: {values.std():.4f}, \"\n",
    "                          f\"Min: {values.min():.4f}, Max: {values.max():.4f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Run comparison\n",
    "comp_res = compare(gss_pred, gss_data)\n",
    "\n",
    "# Display results\n",
    "df_comp = display_results_table(comp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83fec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excellent (>80% acc): 21 variables\n",
      "Good (60-80% acc): 36 variables\n",
      "Poor (30-60% acc): 97 variables\n",
      "Failing (<30% acc): 14 variables\n",
      "Of 171 total predicted variables.\n"
     ]
    }
   ],
   "source": [
    "# Identify which variables work well vs poorly\n",
    "def categorize_performance(comp_res):\n",
    "    excellent = []  # accuracy > 0.8\n",
    "    good = []       # accuracy 0.6-0.8\n",
    "    poor = []       # accuracy 0.3-0.6\n",
    "    failing = []    # accuracy < 0.3\n",
    "    \n",
    "    for var, metrics in comp_res.items():\n",
    "        if 'accuracy' in metrics:\n",
    "            acc = metrics['accuracy']\n",
    "            if acc > 0.8:\n",
    "                excellent.append((var, acc))\n",
    "            elif acc > 0.6:\n",
    "                good.append((var, acc))\n",
    "            elif acc > 0.3:\n",
    "                poor.append((var, acc))\n",
    "            else:\n",
    "                failing.append((var, acc))\n",
    "    \n",
    "    print(f\"Excellent (>80% acc): {len(excellent)} variables\")\n",
    "    print(f\"Good (60-80% acc): {len(good)} variables\")\n",
    "    print(f\"Poor (30-60% acc): {len(poor)} variables\")\n",
    "    print(f\"Failing (<30% acc): {len(failing)} variables\")\n",
    "    print(f\"Of {len(comp_res)} total predicted variables.\")\n",
    "    \n",
    "    return excellent, good, poor, failing\n",
    "\n",
    "excellent, good, poor, failing = categorize_performance(comp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5797629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b95583aa5c24fee8c93cd3d636c431f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='code', options=('abany', 'abdefect', 'abhlth', 'abnomore', 'abpoor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inspect_variable_metrics(code: str) -> None:\n",
    "    \"\"\"\n",
    "    Display metrics for a selected variable.\n",
    "    Shows response type, correlation, accuracy (if categorical), and MAE (if numerical).\n",
    "    \"\"\"\n",
    "    # Header\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"VARIABLE: {code}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Basic information\n",
    "    if code in gss_data:\n",
    "        var_data = gss_data[code]\n",
    "        print(f\"\\nQuestion: {var_data['question']}\")\n",
    "        print(f\"Response Type: {var_data['resp_type'].value}\")\n",
    "        \n",
    "        # Response options (for categorical)\n",
    "        if var_data['resp_type'] == VarType.CATEGORICAL and var_data['resp_to_text']:\n",
    "            print(f\"\\nResponse Options:\")\n",
    "            for val, text in var_data['resp_to_text'].items():\n",
    "                print(f\"  {val}: {text}\")\n",
    "        \n",
    "        # Min/Max (for numerical)\n",
    "        if var_data['resp_type'] in [VarType.INTEGER, VarType.CONTINUOUS] and var_data['min_max']:\n",
    "            print(f\"\\nRange: {var_data['min_max'][0]} to {var_data['min_max'][1]}\")\n",
    "    \n",
    "    # Metrics from comparison\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"METRICS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if code in comp_res:\n",
    "        metrics = comp_res[code]\n",
    "        \n",
    "        # Display metrics based on type\n",
    "        if 'accuracy' in metrics:\n",
    "            # Categorical variable\n",
    "            print(f\"Accuracy:    {metrics['accuracy']:.4f}\")\n",
    "            if not np.isnan(metrics.get('correlation', np.nan)):\n",
    "                print(f\"Correlation: {metrics['correlation']:.4f}\")\n",
    "            else:\n",
    "                print(f\"Correlation: N/A (insufficient variation)\")\n",
    "                \n",
    "        elif 'mae' in metrics:\n",
    "            # Numerical variable\n",
    "            print(f\"MAE:         {metrics['mae']:.4f}\")\n",
    "            if not np.isnan(metrics.get('correlation', np.nan)):\n",
    "                print(f\"Correlation: {metrics['correlation']:.4f}\")\n",
    "            else:\n",
    "                print(f\"Correlation: N/A (insufficient variation)\")\n",
    "    else:\n",
    "        print(\"No metrics available for this variable\")\n",
    "    \n",
    "    # Sample predictions vs actual\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"SAMPLE PREDICTIONS (first 10 valid responses)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if code in gss_pred and code in gss_data:\n",
    "        pred_list = gss_pred[code]['resp_list']\n",
    "        true_list = gss_data[code]['resp_list']\n",
    "        resp_to_text = gss_data[code].get('resp_to_text', {})\n",
    "        \n",
    "        count = 0\n",
    "        print(f\"{'Idx':<5} {'True':<15} {'Predicted':<15} {'Match':<7}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for idx in range(min(len(pred_list), len(true_list))):\n",
    "            if True or (pred_list[idx] is not None and true_list[idx] is not None):\n",
    "                true_val = true_list[idx]\n",
    "                pred_val = pred_list[idx]\n",
    "                \n",
    "                # Format display based on type\n",
    "                if resp_to_text:\n",
    "                    true_display = f\"{true_val} ({resp_to_text.get(true_val, 'unknown')[:10]})\"\n",
    "                    pred_display = f\"{pred_val} ({resp_to_text.get(pred_val, 'unknown')[:10]})\"\n",
    "                else:\n",
    "                    true_display = f\"{true_val:.2f}\" if isinstance(true_val, float) else str(true_val)\n",
    "                    pred_display = f\"{pred_val:.2f}\" if isinstance(pred_val, float) else str(pred_val)\n",
    "                \n",
    "                match = \"✓\" if true_val == pred_val else \"✗\"\n",
    "                print(f\"{idx:<5} {true_display:<15} {pred_display:<15} {match:<7}\")\n",
    "                \n",
    "                count += 1\n",
    "                if count >= 10:\n",
    "                    break\n",
    "\n",
    "# Create interactive widget\n",
    "interact(inspect_variable_metrics, code=sorted(comp_res.keys()));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
